{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dz-web3/DS-Tech-2026spring/blob/main/Module8_LLM_Finetuning/LLM_Finetuning.ipynb)\n",
                "\n",
                "**Click the badge above to open this notebook in Google Colab!**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Module 8: Fine-Tuning Large Language Models (LLMs)\n",
                "\n",
                "**Data Science for Business (Technical) â€” Spring 2026**\n",
                "\n",
                "---\n",
                "\n",
                "## Learning Objectives\n",
                "\n",
                "By the end of this module, you will be able to:\n",
                "\n",
                "1. **Explain** the difference between pre-training, fine-tuning, and prompting\n",
                "2. **Understand** when fine-tuning is the right choice vs. other approaches\n",
                "3. **Perform** hands-on fine-tuning using Hugging Face and LoRA\n",
                "4. **Measure** improvement using before/after evaluation metrics\n",
                "5. **Evaluate** the business value and trade-offs of fine-tuning LLMs\n",
                "\n",
                "---\n",
                "\n",
                "## Why This Matters for Business\n",
                "\n",
                "Large Language Models like GPT-4, Claude, and Qwen are transforming how businesses operate. But **off-the-shelf models don't always fit your specific needs**. Fine-tuning allows you to:\n",
                "\n",
                "- ðŸŽ¯ **Customize** model behavior for your domain (legal, medical, customer service)\n",
                "- ðŸ’° **Reduce costs** by using smaller, specialized models instead of expensive large ones\n",
                "- ðŸ” **Maintain control** over your data and model behavior\n",
                "- âš¡ **Improve performance** on specific tasks your business cares about"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setting Up Google Colab Pro (Free for NYU Students)\n",
                "\n",
                "### ðŸŽ“ NYU Students: Get Free Colab Pro!\n",
                "\n",
                "Google offers **free Colab Pro subscriptions** for students at U.S. higher education institutions.\n",
                "\n",
                "**To claim your free subscription:**\n",
                "\n",
                "1. Go to [colab.research.google.com](https://colab.research.google.com)\n",
                "2. Click on the gear icon (âš™ï¸) â†’ \"Colab Pro\"\n",
                "3. Select \"Colab Pro for Education\"\n",
                "4. Verify your student status using your NYU email\n",
                "5. You'll receive a **1-year free subscription** with more compute resources\n",
                "\n",
                "### ðŸ–¥ï¸ Enabling GPU for This Notebook\n",
                "\n",
                "Fine-tuning requires a GPU. Here's how to enable it:\n",
                "\n",
                "1. Go to **Runtime** â†’ **Change runtime type**\n",
                "2. Set **Hardware accelerator** to **T4 GPU** (or A100 if available with Colab Pro)\n",
                "3. Click **Save**\n",
                "\n",
                "Run the cell below to verify GPU is enabled:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check if GPU is available\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    gpu_name = torch.cuda.get_device_name(0)\n",
                "    print(f\"âœ… GPU is enabled: {gpu_name}\")\n",
                "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "else:\n",
                "    print(\"âŒ GPU is NOT enabled. Please go to Runtime â†’ Change runtime type â†’ Select GPU\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. The LLM Customization Spectrum\n",
                "\n",
                "Before diving into fine-tuning, let's understand where it fits in the broader landscape of LLM customization:\n",
                "\n",
                "| Approach | Effort | Data Needed | Use Case |\n",
                "|----------|--------|-------------|----------|\n",
                "| **Prompting** | Low | None | Quick tasks, general use |\n",
                "| **Few-shot Learning** | Low | 5-20 examples | Demonstrate desired format |\n",
                "| **RAG** (Retrieval) | Medium | Documents | Add knowledge, keep model current |\n",
                "| **Fine-tuning** | High | 100-10,000+ examples | Change model behavior/style |\n",
                "| **Pre-training** | Very High | Billions of tokens | Build from scratch (rarely needed) |\n",
                "\n",
                "### When Should You Fine-Tune?\n",
                "\n",
                "âœ… **Fine-tune when you want to:**\n",
                "- Change the model's communication style consistently\n",
                "- Make the model follow specific formats/templates\n",
                "- Teach domain-specific terminology or behavior\n",
                "- Improve reliability on repetitive tasks\n",
                "\n",
                "âŒ **Don't fine-tune when you can:**\n",
                "- Solve the problem with better prompts\n",
                "- Use RAG to add relevant knowledge\n",
                "- Use few-shot examples in the prompt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Understanding Fine-Tuning: The Concept\n",
                "\n",
                "### Pre-training vs Fine-tuning\n",
                "\n",
                "**Pre-training** is like giving someone a general education:\n",
                "- The model learns from massive amounts of text (books, websites, code)\n",
                "- It learns language patterns, facts, and reasoning\n",
                "- This is expensive: millions of dollars, weeks of compute time\n",
                "- Done by companies like Alibaba (Qwen), Meta (Llama), OpenAI (GPT), Google (Gemini)\n",
                "\n",
                "**Fine-tuning** is like specialized job training:\n",
                "- Start with a pre-trained model that already \"knows\" language\n",
                "- Train it on your specific examples to learn your style/domain\n",
                "- Much cheaper: can be done in minutes to hours on a single GPU\n",
                "- This is what **you** can do!\n",
                "\n",
                "### LoRA: Efficient Fine-Tuning\n",
                "\n",
                "Traditional fine-tuning updates **all** model parameters â€” expensive and slow.\n",
                "\n",
                "**LoRA (Low-Rank Adaptation)** is a clever technique that:\n",
                "- Freezes the original model weights\n",
                "- Adds small \"adapter\" layers that learn your specific task\n",
                "- Only trains ~1% of the parameters\n",
                "- Result: **Same quality, 10x less memory, 10x faster!**\n",
                "\n",
                "Think of it like this: instead of rewriting an entire textbook, you're adding sticky notes with your customizations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Hands-On: Fine-Tuning Qwen2.5\n",
                "\n",
                "Now let's actually fine-tune a model! We'll use:\n",
                "\n",
                "- **Model**: Qwen2.5-0.5B-Instruct (Alibaba's efficient small model)\n",
                "- **Library**: Hugging Face Transformers + PEFT (Parameter-Efficient Fine-Tuning)\n",
                "- **Technique**: LoRA adapters\n",
                "- **Task**: Create a customer service chatbot\n",
                "\n",
                "### Step 1: Install Dependencies\n",
                "\n",
                "This will take about 1-2 minutes. â˜•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "# Install Hugging Face libraries\n",
                "!pip install transformers datasets peft accelerate -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify installation\n",
                "import transformers\n",
                "import peft\n",
                "print(f\"âœ… Transformers version: {transformers.__version__}\")\n",
                "print(f\"âœ… PEFT version: {peft.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2: Load the Base Model (Qwen2.5-0.5B)\n",
                "\n",
                "We'll load Qwen2.5-0.5B-Instruct, an efficient model from Alibaba that's openly available."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
                "import torch\n",
                "\n",
                "# Model configuration - Qwen2.5 is openly available, no approval needed!\n",
                "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
                "\n",
                "# Load the tokenizer\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "tokenizer.padding_side = \"right\"\n",
                "\n",
                "# Load the model\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    model_name,\n",
                "    torch_dtype=torch.float16,\n",
                "    device_map=\"auto\",\n",
                "    trust_remote_code=True,\n",
                ")\n",
                "\n",
                "print(f\"âœ… Model loaded: Qwen2.5-0.5B-Instruct\")\n",
                "print(f\"   Parameters: ~0.5 billion\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3: Prepare the Training Data\n",
                "\n",
                "We'll use a customer service dataset. In real scenarios, you'd use your own business data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample customer service training data\n",
                "training_data = [\n",
                "    {\"instruction\": \"What is your return policy?\", \"response\": \"Our return policy allows returns within 30 days of purchase with a valid receipt. Items must be in original condition with tags attached.\"},\n",
                "    {\"instruction\": \"How do I track my order?\", \"response\": \"You can track your order by logging into your account and clicking 'Order History', or use the tracking number from your shipping confirmation email.\"},\n",
                "    {\"instruction\": \"Do you offer international shipping?\", \"response\": \"Yes, we ship to over 50 countries worldwide. International shipping rates and delivery times vary by destination.\"},\n",
                "    {\"instruction\": \"How can I cancel my order?\", \"response\": \"To cancel an order, please contact us within 2 hours of placing it. Once an order has been processed for shipping, it cannot be cancelled.\"},\n",
                "    {\"instruction\": \"What payment methods do you accept?\", \"response\": \"We accept all major credit cards (Visa, Mastercard, Amex), PayPal, Apple Pay, and Google Pay.\"},\n",
                "    {\"instruction\": \"How do I reset my password?\", \"response\": \"Click 'Forgot Password' on the login page, enter your email, and we'll send you a reset link valid for 24 hours.\"},\n",
                "    {\"instruction\": \"Is my personal information secure?\", \"response\": \"Yes, we use industry-standard SSL encryption and never share your data with third parties. Your security is our priority.\"},\n",
                "    {\"instruction\": \"How do I apply a discount code?\", \"response\": \"Enter your discount code in the 'Promo Code' field at checkout and click 'Apply'. The discount will be reflected in your order total.\"},\n",
                "    {\"instruction\": \"What are your store hours?\", \"response\": \"Our online store is available 24/7. For physical locations, hours vary by store - please check our store locator for specific hours.\"},\n",
                "    {\"instruction\": \"How do I contact customer support?\", \"response\": \"You can reach us via live chat on our website, email at support@example.com, or call 1-800-EXAMPLE Monday-Friday 9am-6pm EST.\"},\n",
                "    {\"instruction\": \"Do you price match?\", \"response\": \"Yes, we offer price matching within 14 days of purchase if you find the same item at a lower price from an authorized retailer.\"},\n",
                "    {\"instruction\": \"How long does shipping take?\", \"response\": \"Standard shipping takes 5-7 business days. Express shipping (2-3 days) and overnight options are also available at checkout.\"},\n",
                "    {\"instruction\": \"Can I change my shipping address?\", \"response\": \"You can update your shipping address before the order ships by contacting customer support. Once shipped, address changes are not possible.\"},\n",
                "    {\"instruction\": \"Do you have a loyalty program?\", \"response\": \"Yes! Join our rewards program for free to earn points on every purchase, receive exclusive discounts, and get early access to sales.\"},\n",
                "    {\"instruction\": \"What if my item arrives damaged?\", \"response\": \"We're sorry to hear that! Please contact us within 48 hours with photos of the damage, and we'll send a replacement or issue a full refund.\"},\n",
                "]\n",
                "\n",
                "print(f\"âœ… Training data prepared: {len(training_data)} examples\")\n",
                "print(f\"\\nExample:\")\n",
                "print(f\"  Q: {training_data[0]['instruction']}\")\n",
                "print(f\"  A: {training_data[0]['response']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. ðŸ“Š BEFORE Fine-Tuning: Baseline Evaluation\n",
                "\n",
                "Before we fine-tune, let's see how the **original model** performs on our customer service questions.\n",
                "\n",
                "This gives us a **baseline** to compare against after fine-tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_response(model, tokenizer, question, system_prompt=\"You are a helpful customer service assistant.\"):\n",
                "    \"\"\"Generate a response from the model\"\"\"\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": system_prompt},\n",
                "        {\"role\": \"user\", \"content\": question}\n",
                "    ]\n",
                "    \n",
                "    # Apply chat template\n",
                "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=150,\n",
                "            temperature=0.7,\n",
                "            do_sample=True,\n",
                "            pad_token_id=tokenizer.eos_token_id,\n",
                "        )\n",
                "    \n",
                "    # Decode and extract response\n",
                "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "    # Extract just the assistant's response (after the last user message)\n",
                "    if question in full_response:\n",
                "        response = full_response.split(question)[-1].strip()\n",
                "    else:\n",
                "        response = full_response\n",
                "    return response[:500]  # Limit length\n",
                "\n",
                "print(\"âœ… Response generator ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test questions for evaluation\n",
                "eval_questions = [\n",
                "    \"What's your return policy?\",\n",
                "    \"How can I track my package?\",\n",
                "    \"Do you ship internationally?\",\n",
                "    \"How do I apply a promo code?\",\n",
                "    \"My order arrived broken, what should I do?\",\n",
                "]\n",
                "\n",
                "# Expected keywords for each question (used for simple evaluation)\n",
                "expected_keywords = [\n",
                "    [\"30 days\", \"return\", \"receipt\", \"original condition\"],\n",
                "    [\"track\", \"order history\", \"tracking number\", \"email\"],\n",
                "    [\"ship\", \"international\", \"countries\", \"worldwide\"],\n",
                "    [\"promo code\", \"discount\", \"checkout\", \"apply\"],\n",
                "    [\"48 hours\", \"photos\", \"replacement\", \"refund\", \"damaged\"],\n",
                "]\n",
                "\n",
                "print(\"ðŸ“‹ Evaluation questions prepared!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_responses(model, tokenizer, questions, expected_keywords):\n",
                "    \"\"\"Evaluate model responses and compute metrics\"\"\"\n",
                "    results = []\n",
                "    total_keywords_found = 0\n",
                "    total_keywords_expected = 0\n",
                "    \n",
                "    for i, question in enumerate(questions):\n",
                "        response = generate_response(model, tokenizer, question)\n",
                "        \n",
                "        # Count how many expected keywords are in the response\n",
                "        keywords_found = sum(1 for kw in expected_keywords[i] if kw.lower() in response.lower())\n",
                "        keywords_expected = len(expected_keywords[i])\n",
                "        \n",
                "        total_keywords_found += keywords_found\n",
                "        total_keywords_expected += keywords_expected\n",
                "        \n",
                "        results.append({\n",
                "            \"question\": question,\n",
                "            \"response\": response,\n",
                "            \"keywords_found\": keywords_found,\n",
                "            \"keywords_expected\": keywords_expected,\n",
                "            \"score\": keywords_found / keywords_expected if keywords_expected > 0 else 0\n",
                "        })\n",
                "    \n",
                "    overall_score = total_keywords_found / total_keywords_expected if total_keywords_expected > 0 else 0\n",
                "    return results, overall_score\n",
                "\n",
                "print(\"ðŸ“Š Evaluating BEFORE fine-tuning...\\n\")\n",
                "before_results, before_score = evaluate_responses(model, tokenizer, eval_questions, expected_keywords)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"BASELINE (Before Fine-Tuning)\")\n",
                "print(\"=\" * 60)\n",
                "for r in before_results:\n",
                "    print(f\"\\nQ: {r['question']}\")\n",
                "    print(f\"A: {r['response'][:200]}...\" if len(r['response']) > 200 else f\"A: {r['response']}\")\n",
                "    print(f\"   Keywords found: {r['keywords_found']}/{r['keywords_expected']} ({r['score']:.0%})\")\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"ðŸ“Š BASELINE SCORE: {before_score:.1%}\")\n",
                "print(f\"{'='*60}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Add LoRA Adapters and Train\n",
                "\n",
                "Now let's add LoRA adapters and fine-tune the model on our customer service data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from peft import LoraConfig, get_peft_model, TaskType\n",
                "\n",
                "# LoRA configuration\n",
                "lora_config = LoraConfig(\n",
                "    r=16,  # LoRA rank\n",
                "    lora_alpha=32,\n",
                "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],  # Attention layers\n",
                "    lora_dropout=0.05,\n",
                "    bias=\"none\",\n",
                "    task_type=TaskType.CAUSAL_LM\n",
                ")\n",
                "\n",
                "# Apply LoRA to the model\n",
                "model = get_peft_model(model, lora_config)\n",
                "\n",
                "# Count trainable parameters\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "\n",
                "print(f\"âœ… LoRA adapters added!\")\n",
                "print(f\"   Trainable parameters: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
                "print(f\"   Total parameters: {total_params:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import Dataset\n",
                "\n",
                "# Format data for training using Qwen chat template\n",
                "def format_and_tokenize(example):\n",
                "    \"\"\"Format the data using Qwen's chat template\"\"\"\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": \"You are a helpful customer service assistant. Be friendly, professional, and concise.\"},\n",
                "        {\"role\": \"user\", \"content\": example['instruction']},\n",
                "        {\"role\": \"assistant\", \"content\": example['response']}\n",
                "    ]\n",
                "    \n",
                "    text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
                "    \n",
                "    # Tokenize\n",
                "    tokens = tokenizer(\n",
                "        text,\n",
                "        truncation=True,\n",
                "        max_length=512,\n",
                "        padding=\"max_length\",\n",
                "        return_tensors=None\n",
                "    )\n",
                "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
                "    return tokens\n",
                "\n",
                "# Create and tokenize dataset\n",
                "dataset = Dataset.from_list(training_data)\n",
                "tokenized_dataset = dataset.map(format_and_tokenize, remove_columns=dataset.column_names)\n",
                "\n",
                "print(f\"âœ… Dataset formatted and tokenized!\")\n",
                "print(f\"   Number of examples: {len(tokenized_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
                "\n",
                "# Data collator for language modeling\n",
                "data_collator = DataCollatorForLanguageModeling(\n",
                "    tokenizer=tokenizer,\n",
                "    mlm=False\n",
                ")\n",
                "\n",
                "# Training configuration\n",
                "# Each parameter explained:\n",
                "# - num_train_epochs: How many times to go through all training examples\n",
                "# - per_device_train_batch_size: Examples processed at once (smaller = less memory)\n",
                "# - gradient_accumulation_steps: Accumulate gradients over N steps before updating\n",
                "# - learning_rate: How big each learning step is\n",
                "# - fp16: Use 16-bit precision (faster, less memory)\n",
                "\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=\"./customer_service_qwen\",\n",
                "    num_train_epochs=10,  # More epochs for better learning\n",
                "    per_device_train_batch_size=1,  # Small batch size\n",
                "    gradient_accumulation_steps=2,  # Effective batch size = 1 * 2 = 2\n",
                "    learning_rate=2e-4,\n",
                "    logging_steps=10,\n",
                "    save_strategy=\"no\",\n",
                "    report_to=\"none\",\n",
                "    fp16=True,\n",
                "    warmup_steps=10,\n",
                ")\n",
                "\n",
                "# Create trainer\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_dataset,\n",
                "    data_collator=data_collator,\n",
                ")\n",
                "\n",
                "print(\"ðŸš€ Starting training...\")\n",
                "print(f\"   Training examples: {len(tokenized_dataset)}\")\n",
                "print(f\"   Epochs: {training_args.num_train_epochs}\")\n",
                "print(f\"   Batch size: {training_args.per_device_train_batch_size} x {training_args.gradient_accumulation_steps} = {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
                "print(f\"   Estimated steps: ~{len(tokenized_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) * training_args.num_train_epochs}\")\n",
                "print(\"   Watch the 'loss' value decrease - that means learning is happening!\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run training\n",
                "trainer.train()\n",
                "\n",
                "print(f\"\\nâœ… Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. ðŸ“Š AFTER Fine-Tuning: Measure Improvement\n",
                "\n",
                "Now let's evaluate the **fine-tuned model** and compare to our baseline!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set model to evaluation mode\n",
                "model.eval()\n",
                "\n",
                "print(\"ðŸ“Š Evaluating AFTER fine-tuning...\\n\")\n",
                "after_results, after_score = evaluate_responses(model, tokenizer, eval_questions, expected_keywords)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"AFTER FINE-TUNING\")\n",
                "print(\"=\" * 60)\n",
                "for r in after_results:\n",
                "    print(f\"\\nQ: {r['question']}\")\n",
                "    print(f\"A: {r['response'][:200]}...\" if len(r['response']) > 200 else f\"A: {r['response']}\")\n",
                "    print(f\"   Keywords found: {r['keywords_found']}/{r['keywords_expected']} ({r['score']:.0%})\")\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"ðŸ“Š AFTER SCORE: {after_score:.1%}\")\n",
                "print(f\"{'='*60}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print comparison\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"ðŸ“ˆ IMPROVEMENT SUMMARY\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\n   BEFORE Fine-Tuning: {before_score:.1%}\")\n",
                "print(f\"   AFTER Fine-Tuning:  {after_score:.1%}\")\n",
                "print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
                "\n",
                "improvement = after_score - before_score\n",
                "if improvement > 0:\n",
                "    print(f\"   ðŸ“ˆ IMPROVEMENT: +{improvement:.1%}\")\n",
                "    print(f\"\\n   âœ… Fine-tuning improved the model's responses!\")\n",
                "elif improvement < 0:\n",
                "    print(f\"   ðŸ“‰ Change: {improvement:.1%}\")\n",
                "    print(f\"\\n   âš ï¸ The model may need more training data or epochs.\")\n",
                "else:\n",
                "    print(f\"   â†’ No change\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Test with Your Own Questions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test with NEW questions (not in training data)\n",
                "new_questions = [\n",
                "    \"Can I get a refund if I don't like the product?\",\n",
                "    \"What happens if my package is lost?\",\n",
                "    \"Do you have a size guide?\",\n",
                "]\n",
                "\n",
                "print(\"ðŸ†• Testing with NEW questions (not in training data):\\n\")\n",
                "for q in new_questions:\n",
                "    response = generate_response(model, tokenizer, q)\n",
                "    print(f\"Customer: {q}\")\n",
                "    print(f\"Bot: {response}\")\n",
                "    print(\"-\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Save the Model (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the LoRA adapters (small, ~20MB)\n",
                "model.save_pretrained(\"customer_service_lora\")\n",
                "tokenizer.save_pretrained(\"customer_service_lora\")\n",
                "print(\"âœ… Model saved to 'customer_service_lora' folder\")\n",
                "\n",
                "# Check the size\n",
                "!du -sh customer_service_lora/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Summary & Key Takeaways\n",
                "\n",
                "### What We Learned\n",
                "\n",
                "1. **Fine-tuning** adapts a pre-trained model to your specific needs\n",
                "2. **LoRA** makes fine-tuning efficient (train only ~1% of parameters)\n",
                "3. **Evaluation metrics** help you measure if fine-tuning improved performance\n",
                "4. **Business value** comes from consistency, cost reduction, and customization\n",
                "\n",
                "### What We Did\n",
                "\n",
                "- âœ… Loaded Qwen2.5-0.5B (a 0.5 billion parameter model)\n",
                "- âœ… Established a **baseline** before fine-tuning\n",
                "- âœ… Added LoRA adapters for efficient training\n",
                "- âœ… Fine-tuned on customer service data\n",
                "- âœ… **Measured improvement** with before/after comparison\n",
                "- âœ… Tested the model on new questions\n",
                "\n",
                "### Next Steps for Your Career\n",
                "\n",
                "1. **Experiment**: Try fine-tuning with your own data\n",
                "2. **Explore**: Look into Hugging Face Hub, OpenAI fine-tuning API\n",
                "3. **Stay current**: This field moves fast â€” follow AI news!\n",
                "\n",
                "---\n",
                "\n",
                "*Questions? Reach out during office hours or on the course forum.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“ Required Tasks\n",
                "\n",
                "Complete the following two task notebooks to practice what you've learned:\n",
                "\n",
                "### Task 1: Sentiment Fine-Tuning\n",
                "**Notebook**: `Task1_Sentiment_Finetuning.ipynb`\n",
                "\n",
                "[![Open Task 1 in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dz-web3/DS-Tech-2026spring/blob/main/Module8_LLM_Finetuning/Task1_Sentiment_Finetuning.ipynb)\n",
                "\n",
                "In this task, you will:\n",
                "- Fine-tune a model on product reviews\n",
                "- Add your own training examples\n",
                "- Test the model on custom text\n",
                "\n",
                "---\n",
                "\n",
                "### Task 2: Prompting vs Fine-Tuning\n",
                "**Notebook**: `Task2_Prompting_vs_Finetuning.ipynb`\n",
                "\n",
                "[![Open Task 2 in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dz-web3/DS-Tech-2026spring/blob/main/Module8_LLM_Finetuning/Task2_Prompting_vs_Finetuning.ipynb)\n",
                "\n",
                "In this task, you will:\n",
                "- Compare zero-shot vs few-shot prompting\n",
                "- Improve prompts for better responses\n",
                "- Create a decision framework for business scenarios"
            ]
        }
    ]
}