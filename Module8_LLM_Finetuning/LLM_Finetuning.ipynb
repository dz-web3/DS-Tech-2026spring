{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dz-web3/DS-Tech-2026spring/blob/main/Module8_LLM_Finetuning/LLM_Finetuning.ipynb)\n",
                "\n",
                "**Click the badge above to open this notebook in Google Colab!**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Module 8: Fine-Tuning Large Language Models (LLMs)\n",
                "\n",
                "**Data Science for Business (Technical) ‚Äî Spring 2026**\n",
                "\n",
                "---\n",
                "\n",
                "## Learning Objectives\n",
                "\n",
                "By the end of this module, you will be able to:\n",
                "\n",
                "1. **Explain** the difference between pre-training, fine-tuning, and prompting\n",
                "2. **Understand** when fine-tuning is the right choice vs. other approaches\n",
                "3. **Perform** hands-on fine-tuning using Hugging Face and LoRA\n",
                "4. **Visualize** training loss and detect overfitting\n",
                "5. **Measure** improvement using before/after evaluation on held-out test data\n",
                "\n",
                "---\n",
                "\n",
                "## Why This Matters for Business\n",
                "\n",
                "Large Language Models like GPT-4, Claude, and Qwen are transforming how businesses operate. But **off-the-shelf models don't always fit your specific needs**. Fine-tuning allows you to:\n",
                "\n",
                "- üéØ **Customize** model behavior for your domain (legal, medical, customer service)\n",
                "- üí∞ **Reduce costs** by using smaller, specialized models instead of expensive large ones\n",
                "- üîê **Maintain control** over your data and model behavior\n",
                "- ‚ö° **Improve performance** on specific tasks your business cares about"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setting Up Google Colab Pro (Free for NYU Students)\n",
                "\n",
                "### üéì NYU Students: Get Free Colab Pro!\n",
                "\n",
                "Google offers **free Colab Pro subscriptions** for students at U.S. higher education institutions.\n",
                "\n",
                "**To claim your free subscription:**\n",
                "\n",
                "1. Go to [colab.research.google.com](https://colab.research.google.com)\n",
                "2. Click on the gear icon (‚öôÔ∏è) ‚Üí \"Colab Pro\"\n",
                "3. Select \"Colab Pro for Education\"\n",
                "4. Verify your student status using your NYU email\n",
                "5. You'll receive a **1-year free subscription** with more compute resources\n",
                "\n",
                "### üñ•Ô∏è Enabling GPU for This Notebook\n",
                "\n",
                "Fine-tuning requires a GPU. Here's how to enable it:\n",
                "\n",
                "1. Go to **Runtime** ‚Üí **Change runtime type**\n",
                "2. Set **Hardware accelerator** to **T4 GPU** (or A100 if available with Colab Pro)\n",
                "3. Click **Save**\n",
                "\n",
                "Run the cell below to verify GPU is enabled:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check if GPU is available\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    gpu_name = torch.cuda.get_device_name(0)\n",
                "    print(f\"‚úÖ GPU is enabled: {gpu_name}\")\n",
                "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "else:\n",
                "    print(\"‚ùå GPU is NOT enabled. Please go to Runtime ‚Üí Change runtime type ‚Üí Select GPU\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. The LLM Customization Spectrum\n",
                "\n",
                "Before diving into fine-tuning, let's understand where it fits in the broader landscape of LLM customization:\n",
                "\n",
                "| Approach | Effort | Data Needed | Use Case |\n",
                "|----------|--------|-------------|----------|\n",
                "| **Prompting** | Low | None | Quick tasks, general use |\n",
                "| **Few-shot Learning** | Low | 5-20 examples | Demonstrate desired format |\n",
                "| **RAG** (Retrieval) | Medium | Documents | Add knowledge, keep model current |\n",
                "| **Fine-tuning** | High | 100-10,000+ examples | Change model behavior/style |\n",
                "| **Pre-training** | Very High | Billions of tokens | Build from scratch (rarely needed) |\n",
                "\n",
                "### When Should You Fine-Tune?\n",
                "\n",
                "‚úÖ **Fine-tune when you want to:**\n",
                "- Change the model's communication style consistently\n",
                "- Make the model follow specific formats/templates\n",
                "- Teach domain-specific terminology or behavior\n",
                "- Improve reliability on repetitive tasks\n",
                "\n",
                "‚ùå **Don't fine-tune when you can:**\n",
                "- Solve the problem with better prompts\n",
                "- Use RAG to add relevant knowledge\n",
                "- Use few-shot examples in the prompt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Understanding Fine-Tuning: The Concept\n",
                "\n",
                "### Pre-training vs Fine-tuning\n",
                "\n",
                "**Pre-training** is like giving someone a general education:\n",
                "- The model learns from massive amounts of text (books, websites, code)\n",
                "- It learns language patterns, facts, and reasoning\n",
                "- This is expensive: millions of dollars, weeks of compute time\n",
                "- Done by companies like Alibaba (Qwen), Meta (Llama), OpenAI (GPT), Google (Gemini)\n",
                "\n",
                "**Fine-tuning** is like specialized job training:\n",
                "- Start with a pre-trained model that already \"knows\" language\n",
                "- Train it on your specific examples to learn your style/domain\n",
                "- Much cheaper: can be done in minutes to hours on a single GPU\n",
                "- This is what **you** can do!\n",
                "\n",
                "### LoRA: Efficient Fine-Tuning\n",
                "\n",
                "Traditional fine-tuning updates **all** model parameters ‚Äî expensive and slow.\n",
                "\n",
                "**LoRA (Low-Rank Adaptation)** is a clever technique that:\n",
                "- Freezes the original model weights\n",
                "- Adds small \"adapter\" layers that learn your specific task\n",
                "- Only trains ~1% of the parameters\n",
                "- Result: **Same quality, 10x less memory, 10x faster!**\n",
                "\n",
                "Think of it like this: instead of rewriting an entire textbook, you're adding sticky notes with your customizations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Hands-On: Fine-Tuning Qwen2.5\n",
                "\n",
                "Now let's actually fine-tune a model! We'll use:\n",
                "\n",
                "- **Model**: Qwen2.5-0.5B-Instruct (Alibaba's efficient small model)\n",
                "- **Library**: Hugging Face Transformers + PEFT (Parameter-Efficient Fine-Tuning)\n",
                "- **Technique**: LoRA adapters\n",
                "- **Task**: Create a customer service chatbot\n",
                "\n",
                "### Step 1: Install Dependencies\n",
                "\n",
                "This will take about 1-2 minutes. ‚òï"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "# Install Hugging Face libraries\n",
                "!pip install transformers datasets peft accelerate matplotlib -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify installation\n",
                "import transformers\n",
                "import peft\n",
                "import matplotlib.pyplot as plt\n",
                "print(f\"‚úÖ Transformers version: {transformers.__version__}\")\n",
                "print(f\"‚úÖ PEFT version: {peft.__version__}\")\n",
                "print(f\"‚úÖ Matplotlib ready for visualization\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2: Load the Base Model (Qwen2.5-0.5B)\n",
                "\n",
                "We'll load Qwen2.5-0.5B-Instruct, an efficient model from Alibaba that's openly available."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
                "import torch\n",
                "\n",
                "# Model configuration - Qwen2.5 is openly available, no approval needed!\n",
                "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
                "\n",
                "# Load the tokenizer\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "tokenizer.padding_side = \"right\"\n",
                "\n",
                "# Load the model\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    model_name,\n",
                "    torch_dtype=torch.float16,\n",
                "    device_map=\"auto\",\n",
                "    trust_remote_code=True,\n",
                ")\n",
                "\n",
                "print(f\"‚úÖ Model loaded: Qwen2.5-0.5B-Instruct\")\n",
                "print(f\"   Parameters: ~0.5 billion\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3: Prepare Training and Test Data\n",
                "\n",
                "We split our data into:\n",
                "- **Training data**: Used to fine-tune the model\n",
                "- **Test data**: Held out to evaluate improvement (model never sees this during training)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TRAINING DATA - The model will learn from these examples\n",
                "training_data = [\n",
                "    {\"instruction\": \"What is your return policy?\", \"response\": \"Our return policy allows returns within 30 days of purchase with a valid receipt. Items must be in original condition with tags attached.\"},\n",
                "    {\"instruction\": \"How do I track my order?\", \"response\": \"You can track your order by logging into your account and clicking 'Order History', or use the tracking number from your shipping confirmation email.\"},\n",
                "    {\"instruction\": \"Do you offer international shipping?\", \"response\": \"Yes, we ship to over 50 countries worldwide. International shipping rates and delivery times vary by destination.\"},\n",
                "    {\"instruction\": \"How can I cancel my order?\", \"response\": \"To cancel an order, please contact us within 2 hours of placing it. Once an order has been processed for shipping, it cannot be cancelled.\"},\n",
                "    {\"instruction\": \"What payment methods do you accept?\", \"response\": \"We accept all major credit cards (Visa, Mastercard, Amex), PayPal, Apple Pay, and Google Pay.\"},\n",
                "    {\"instruction\": \"How do I reset my password?\", \"response\": \"Click 'Forgot Password' on the login page, enter your email, and we'll send you a reset link valid for 24 hours.\"},\n",
                "    {\"instruction\": \"Is my personal information secure?\", \"response\": \"Yes, we use industry-standard SSL encryption and never share your data with third parties. Your security is our priority.\"},\n",
                "    {\"instruction\": \"How do I apply a discount code?\", \"response\": \"Enter your discount code in the 'Promo Code' field at checkout and click 'Apply'. The discount will be reflected in your order total.\"},\n",
                "    {\"instruction\": \"What are your store hours?\", \"response\": \"Our online store is available 24/7. For physical locations, hours vary by store - please check our store locator for specific hours.\"},\n",
                "    {\"instruction\": \"How do I contact customer support?\", \"response\": \"You can reach us via live chat on our website, email at support@example.com, or call 1-800-EXAMPLE Monday-Friday 9am-6pm EST.\"},\n",
                "]\n",
                "\n",
                "# TEST DATA - Held out for evaluation (model never sees these during training!)\n",
                "test_data = [\n",
                "    {\"instruction\": \"Do you price match?\", \"response\": \"Yes, we offer price matching within 14 days of purchase if you find the same item at a lower price from an authorized retailer.\"},\n",
                "    {\"instruction\": \"How long does shipping take?\", \"response\": \"Standard shipping takes 5-7 business days. Express shipping (2-3 days) and overnight options are also available at checkout.\"},\n",
                "    {\"instruction\": \"Can I change my shipping address?\", \"response\": \"You can update your shipping address before the order ships by contacting customer support. Once shipped, address changes are not possible.\"},\n",
                "    {\"instruction\": \"Do you have a loyalty program?\", \"response\": \"Yes! Join our rewards program for free to earn points on every purchase, receive exclusive discounts, and get early access to sales.\"},\n",
                "    {\"instruction\": \"What if my item arrives damaged?\", \"response\": \"We're sorry to hear that! Please contact us within 48 hours with photos of the damage, and we'll send a replacement or issue a full refund.\"},\n",
                "]\n",
                "\n",
                "print(f\"‚úÖ Data prepared!\")\n",
                "print(f\"   Training examples: {len(training_data)} (used for fine-tuning)\")\n",
                "print(f\"   Test examples: {len(test_data)} (held out for evaluation)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. üìä BEFORE Fine-Tuning: Baseline Evaluation\n",
                "\n",
                "Before we fine-tune, let's see how the **original model** performs on our **test data**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_response(model, tokenizer, question, system_prompt=\"You are a helpful customer service assistant.\"):\n",
                "    \"\"\"Generate a response from the model\"\"\"\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": system_prompt},\n",
                "        {\"role\": \"user\", \"content\": question}\n",
                "    ]\n",
                "    \n",
                "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=150,\n",
                "            temperature=0.7,\n",
                "            do_sample=True,\n",
                "            pad_token_id=tokenizer.eos_token_id,\n",
                "        )\n",
                "    \n",
                "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "    if question in full_response:\n",
                "        response = full_response.split(question)[-1].strip()\n",
                "    else:\n",
                "        response = full_response\n",
                "    return response[:500]\n",
                "\n",
                "def evaluate_on_test_data(model, tokenizer, test_data):\n",
                "    \"\"\"Evaluate model on test data\"\"\"\n",
                "    results = []\n",
                "    total_keyword_score = 0\n",
                "    \n",
                "    for item in test_data:\n",
                "        question = item[\"instruction\"]\n",
                "        expected = item[\"response\"]\n",
                "        generated = generate_response(model, tokenizer, question)\n",
                "        \n",
                "        expected_keywords = set(word.lower() for word in expected.split() if len(word) >= 4)\n",
                "        generated_lower = generated.lower()\n",
                "        \n",
                "        keywords_found = sum(1 for kw in expected_keywords if kw in generated_lower)\n",
                "        keyword_score = keywords_found / len(expected_keywords) if expected_keywords else 0\n",
                "        total_keyword_score += keyword_score\n",
                "        \n",
                "        results.append({\"question\": question, \"expected\": expected, \"generated\": generated, \"keyword_score\": keyword_score})\n",
                "    \n",
                "    return results, total_keyword_score / len(test_data)\n",
                "\n",
                "print(\"üìä Evaluating BEFORE fine-tuning...\\n\")\n",
                "before_results, before_score = evaluate_on_test_data(model, tokenizer, test_data)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(f\"BASELINE SCORE: {before_score:.1%}\")\n",
                "print(\"=\" * 60)\n",
                "for r in before_results:\n",
                "    print(f\"\\n‚ùì {r['question']}\")\n",
                "    print(f\"   Score: {r['keyword_score']:.0%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Add LoRA Adapters and Train\n",
                "\n",
                "Now let's add LoRA adapters and fine-tune the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from peft import LoraConfig, get_peft_model, TaskType\n",
                "\n",
                "# LoRA configuration\n",
                "lora_config = LoraConfig(\n",
                "    r=16,\n",
                "    lora_alpha=32,\n",
                "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
                "    lora_dropout=0.05,\n",
                "    bias=\"none\",\n",
                "    task_type=TaskType.CAUSAL_LM\n",
                ")\n",
                "\n",
                "model = get_peft_model(model, lora_config)\n",
                "\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "\n",
                "print(f\"‚úÖ LoRA adapters added!\")\n",
                "print(f\"   Trainable: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import Dataset\n",
                "\n",
                "def format_and_tokenize(example):\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": \"You are a helpful customer service assistant. Be friendly, professional, and concise.\"},\n",
                "        {\"role\": \"user\", \"content\": example['instruction']},\n",
                "        {\"role\": \"assistant\", \"content\": example['response']}\n",
                "    ]\n",
                "    text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
                "    tokens = tokenizer(text, truncation=True, max_length=512, padding=\"max_length\", return_tensors=None)\n",
                "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
                "    return tokens\n",
                "\n",
                "dataset = Dataset.from_list(training_data)\n",
                "tokenized_dataset = dataset.map(format_and_tokenize, remove_columns=dataset.column_names)\n",
                "\n",
                "print(f\"‚úÖ Dataset ready: {len(tokenized_dataset)} training examples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling, TrainerCallback\n",
                "\n",
                "# Custom callback to track training metrics\n",
                "class TrainingMetricsCallback(TrainerCallback):\n",
                "    def __init__(self):\n",
                "        self.training_loss = []\n",
                "        self.steps = []\n",
                "    \n",
                "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
                "        if logs and \"loss\" in logs:\n",
                "            self.training_loss.append(logs[\"loss\"])\n",
                "            self.steps.append(state.global_step)\n",
                "\n",
                "metrics_callback = TrainingMetricsCallback()\n",
                "\n",
                "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
                "\n",
                "# Training configuration - 15 epochs\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=\"./customer_service_qwen\",\n",
                "    num_train_epochs=15,\n",
                "    per_device_train_batch_size=1,\n",
                "    gradient_accumulation_steps=2,\n",
                "    learning_rate=2e-4,\n",
                "    logging_steps=5,  # Log every 5 steps\n",
                "    save_strategy=\"no\",\n",
                "    report_to=\"none\",\n",
                "    fp16=True,\n",
                "    warmup_steps=10,\n",
                ")\n",
                "\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_dataset,\n",
                "    data_collator=data_collator,\n",
                "    callbacks=[metrics_callback],\n",
                ")\n",
                "\n",
                "print(\"üöÄ Starting training for 15 epochs...\")\n",
                "print(f\"   Training examples: {len(tokenized_dataset)}\")\n",
                "print(\"   Watch the loss decrease!\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run training\n",
                "train_result = trainer.train()\n",
                "\n",
                "print(f\"\\n‚úÖ Training complete!\")\n",
                "print(f\"   Final training loss: {train_result.training_loss:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. üìà Visualize Training Loss\n",
                "\n",
                "Let's plot the training loss to see how the model learned and detect potential overfitting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Plot training loss\n",
                "plt.figure(figsize=(10, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(metrics_callback.steps, metrics_callback.training_loss, 'b-', linewidth=2, label='Training Loss')\n",
                "plt.xlabel('Training Steps', fontsize=12)\n",
                "plt.ylabel('Loss', fontsize=12)\n",
                "plt.title('Training Loss Over Time', fontsize=14)\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "# Add epoch markers\n",
                "steps_per_epoch = len(tokenized_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)\n",
                "if steps_per_epoch > 0:\n",
                "    for epoch in range(1, int(training_args.num_train_epochs) + 1):\n",
                "        epoch_step = epoch * steps_per_epoch\n",
                "        if epoch_step <= max(metrics_callback.steps):\n",
                "            plt.axvline(x=epoch_step, color='gray', linestyle='--', alpha=0.5)\n",
                "\n",
                "# Plot smoothed loss (moving average)\n",
                "plt.subplot(1, 2, 2)\n",
                "window_size = min(5, len(metrics_callback.training_loss))\n",
                "if window_size > 1:\n",
                "    smoothed_loss = [sum(metrics_callback.training_loss[max(0,i-window_size):i+1])/min(i+1, window_size) \n",
                "                    for i in range(len(metrics_callback.training_loss))]\n",
                "    plt.plot(metrics_callback.steps, smoothed_loss, 'r-', linewidth=2, label='Smoothed Loss')\n",
                "else:\n",
                "    plt.plot(metrics_callback.steps, metrics_callback.training_loss, 'r-', linewidth=2, label='Training Loss')\n",
                "plt.xlabel('Training Steps', fontsize=12)\n",
                "plt.ylabel('Loss (Smoothed)', fontsize=12)\n",
                "plt.title('Smoothed Training Loss', fontsize=14)\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Print analysis\n",
                "print(\"\\nüìä TRAINING ANALYSIS:\")\n",
                "print(\"=\"*50)\n",
                "if len(metrics_callback.training_loss) >= 2:\n",
                "    initial_loss = metrics_callback.training_loss[0]\n",
                "    final_loss = metrics_callback.training_loss[-1]\n",
                "    print(f\"   Initial loss: {initial_loss:.4f}\")\n",
                "    print(f\"   Final loss:   {final_loss:.4f}\")\n",
                "    print(f\"   Reduction:    {(initial_loss - final_loss) / initial_loss * 100:.1f}%\")\n",
                "    \n",
                "    # Check for overfitting signs\n",
                "    mid_point = len(metrics_callback.training_loss) // 2\n",
                "    first_half_avg = sum(metrics_callback.training_loss[:mid_point]) / mid_point if mid_point > 0 else 0\n",
                "    second_half_avg = sum(metrics_callback.training_loss[mid_point:]) / (len(metrics_callback.training_loss) - mid_point)\n",
                "    \n",
                "    if second_half_avg < first_half_avg * 0.5:\n",
                "        print(\"\\n   ‚ö†Ô∏è Loss is very low - watch for overfitting!\")\n",
                "        print(\"   Consider: fewer epochs, more regularization, or more data.\")\n",
                "    else:\n",
                "        print(\"\\n   ‚úÖ Training looks healthy - loss is decreasing steadily.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. üìä AFTER Fine-Tuning: Measure Real Improvement\n",
                "\n",
                "Now let's evaluate on **held-out test data** to see the real gain!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "\n",
                "print(\"üìä Evaluating AFTER fine-tuning on TEST DATA...\\n\")\n",
                "after_results, after_score = evaluate_on_test_data(model, tokenizer, test_data)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"AFTER FINE-TUNING - TEST DATA\")\n",
                "print(\"=\" * 60)\n",
                "for r in after_results:\n",
                "    print(f\"\\n‚ùì {r['question']}\")\n",
                "    print(f\"ü§ñ {r['generated'][:150]}...\" if len(r['generated']) > 150 else f\"ü§ñ {r['generated']}\")\n",
                "    print(f\"   Score: {r['keyword_score']:.0%}\")\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"üìä AFTER SCORE: {after_score:.1%}\")\n",
                "print(f\"{'='*60}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize before/after comparison\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "# Bar chart comparing scores\n",
                "scores = [before_score * 100, after_score * 100]\n",
                "labels = ['Before\\nFine-Tuning', 'After\\nFine-Tuning']\n",
                "colors = ['#ff6b6b', '#51cf66']\n",
                "\n",
                "axes[0].bar(labels, scores, color=colors, edgecolor='black', linewidth=1.5)\n",
                "axes[0].set_ylabel('Score (%)', fontsize=12)\n",
                "axes[0].set_title('Overall Test Score Comparison', fontsize=14)\n",
                "axes[0].set_ylim(0, 100)\n",
                "for i, v in enumerate(scores):\n",
                "    axes[0].text(i, v + 2, f'{v:.1f}%', ha='center', fontsize=12, fontweight='bold')\n",
                "\n",
                "# Per-question comparison\n",
                "questions_short = [f\"Q{i+1}\" for i in range(len(test_data))]\n",
                "before_scores = [r['keyword_score'] * 100 for r in before_results]\n",
                "after_scores = [r['keyword_score'] * 100 for r in after_results]\n",
                "\n",
                "x = range(len(questions_short))\n",
                "width = 0.35\n",
                "axes[1].bar([i - width/2 for i in x], before_scores, width, label='Before', color='#ff6b6b')\n",
                "axes[1].bar([i + width/2 for i in x], after_scores, width, label='After', color='#51cf66')\n",
                "axes[1].set_xticks(x)\n",
                "axes[1].set_xticklabels(questions_short)\n",
                "axes[1].set_ylabel('Score (%)', fontsize=12)\n",
                "axes[1].set_title('Per-Question Score Comparison', fontsize=14)\n",
                "axes[1].legend()\n",
                "axes[1].set_ylim(0, 100)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Print summary\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"üìà IMPROVEMENT SUMMARY\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\n   BEFORE: {before_score:.1%}\")\n",
                "print(f\"   AFTER:  {after_score:.1%}\")\n",
                "improvement = after_score - before_score\n",
                "if improvement > 0:\n",
                "    print(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
                "    print(f\"   üìà GAIN: +{improvement:.1%}\")\n",
                "    print(f\"\\n   ‚úÖ Fine-tuning improved performance on unseen test data!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Test with Your Own Questions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "new_questions = [\n",
                "    \"Can I get a refund if I don't like the product?\",\n",
                "    \"What happens if my package is lost?\",\n",
                "    \"Do you have a size guide?\",\n",
                "]\n",
                "\n",
                "print(\"üÜï Testing with completely NEW questions:\\n\")\n",
                "for q in new_questions:\n",
                "    response = generate_response(model, tokenizer, q)\n",
                "    print(f\"Customer: {q}\")\n",
                "    print(f\"Bot: {response}\")\n",
                "    print(\"-\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Save the Model (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save_pretrained(\"customer_service_lora\")\n",
                "tokenizer.save_pretrained(\"customer_service_lora\")\n",
                "print(\"‚úÖ Model saved!\")\n",
                "!du -sh customer_service_lora/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Summary & Key Takeaways\n",
                "\n",
                "### What We Learned\n",
                "\n",
                "1. **Fine-tuning** adapts a pre-trained model to your specific needs\n",
                "2. **LoRA** makes fine-tuning efficient (train only ~1% of parameters)\n",
                "3. **Training curves** help you monitor learning and detect overfitting\n",
                "4. **Train/Test split** is essential to measure real improvement\n",
                "\n",
                "### What We Did\n",
                "\n",
                "- ‚úÖ Loaded Qwen2.5-0.5B (0.5 billion parameters)\n",
                "- ‚úÖ Split data: 10 training, 5 test examples\n",
                "- ‚úÖ Added LoRA adapters\n",
                "- ‚úÖ Trained for 15 epochs with loss visualization\n",
                "- ‚úÖ Measured improvement on unseen test data\n",
                "\n",
                "---\n",
                "\n",
                "*Questions? Reach out during office hours or on the course forum.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù Required Tasks\n",
                "\n",
                "Complete the following two task notebooks to practice what you've learned:\n",
                "\n",
                "### Task 1: Sentiment Fine-Tuning\n",
                "**Notebook**: `Task1_Sentiment_Finetuning.ipynb`\n",
                "\n",
                "[![Open Task 1 in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dz-web3/DS-Tech-2026spring/blob/main/Module8_LLM_Finetuning/Task1_Sentiment_Finetuning.ipynb)\n",
                "\n",
                "---\n",
                "\n",
                "### Task 2: Prompting vs Fine-Tuning\n",
                "**Notebook**: `Task2_Prompting_vs_Finetuning.ipynb`\n",
                "\n",
                "[![Open Task 2 in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dz-web3/DS-Tech-2026spring/blob/main/Module8_LLM_Finetuning/Task2_Prompting_vs_Finetuning.ipynb)"
            ]
        }
    ]
}