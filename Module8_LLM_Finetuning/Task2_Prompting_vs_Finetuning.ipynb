{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dz-web3/DS-Tech-2026spring/blob/main/Module8_LLM_Finetuning/Task2_Prompting_vs_Finetuning.ipynb)\n",
                "\n",
                "**Click the badge above to open this notebook in Google Colab!**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 2: Prompting vs Fine-Tuning\n",
                "\n",
                "**Data Science for Business (Technical) ‚Äî Spring 2026**\n",
                "\n",
                "---\n",
                "\n",
                "## üéØ Learning Goals\n",
                "\n",
                "In this task, you will:\n",
                "1. **Compare** zero-shot, few-shot, and fine-tuned approaches\n",
                "2. **Experiment** with prompt engineering techniques\n",
                "3. **Analyze** trade-offs between different LLM customization methods\n",
                "4. **Decide** which approach is best for a business scenario\n",
                "\n",
                "---\n",
                "\n",
                "## üìã What You Need to Do\n",
                "\n",
                "1. **First**: Run all the cells to see the comparison demo\n",
                "2. **Then**: Complete the 3 exercises marked with ‚úèÔ∏è\n",
                "3. **Finally**: Write your recommendation in the final section\n",
                "\n",
                "**Estimated time**: 20-30 minutes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Setup (Just Run This Cell)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "# Install required libraries\n",
                "!pip install transformers accelerate -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from transformers import pipeline\n",
                "\n",
                "# Check GPU\n",
                "device = 0 if torch.cuda.is_available() else -1\n",
                "if device == 0:\n",
                "    print(f\"‚úÖ GPU enabled: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Running on CPU (slower). Consider enabling GPU.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The Business Scenario\n",
                "\n",
                "You're building a **customer service chatbot** for an e-commerce company. The bot needs to:\n",
                "- Answer common questions (returns, shipping, payments)\n",
                "- Maintain a professional, helpful tone\n",
                "- Provide accurate information\n",
                "\n",
                "Let's compare three approaches:\n",
                "\n",
                "| Approach | Description | Effort |\n",
                "|----------|-------------|--------|\n",
                "| **Zero-shot** | Just describe the task, no examples | Low |\n",
                "| **Few-shot** | Provide a few examples in the prompt | Medium |\n",
                "| **Fine-tuning** | Train on custom data | High |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Load a Language Model\n",
                "\n",
                "We'll use **Flan-T5**, a model that's good at following instructions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the text-generation pipeline\n",
                "print(\"Loading model... (this may take a minute)\")\n",
                "\n",
                "generator = pipeline(\n",
                "    \"text2text-generation\",\n",
                "    model=\"google/flan-t5-base\",\n",
                "    device=device,\n",
                "    max_new_tokens=150\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Model loaded: Flan-T5-Base\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Approach 1: Zero-Shot Prompting\n",
                "\n",
                "In zero-shot, we simply describe what we want without any examples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Zero-shot prompt\n",
                "def ask_zero_shot(question):\n",
                "    prompt = f\"\"\"You are a helpful customer service assistant for an online store.\n",
                "Answer the following customer question:\n",
                "\n",
                "Question: {question}\n",
                "Answer:\"\"\"\n",
                "    \n",
                "    response = generator(prompt)[0]['generated_text']\n",
                "    return response.strip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test zero-shot on common questions\n",
                "test_questions = [\n",
                "    \"What is your return policy?\",\n",
                "    \"How do I track my order?\",\n",
                "    \"Do you accept PayPal?\",\n",
                "]\n",
                "\n",
                "print(\"üìã ZERO-SHOT RESULTS:\\n\")\n",
                "for q in test_questions:\n",
                "    print(f\"Q: {q}\")\n",
                "    print(f\"A: {ask_zero_shot(q)}\")\n",
                "    print(\"-\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Approach 2: Few-Shot Prompting\n",
                "\n",
                "In few-shot, we provide examples of desired input-output pairs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Few-shot examples\n",
                "few_shot_examples = \"\"\"\n",
                "Example 1:\n",
                "Question: What is your return policy?\n",
                "Answer: We offer a 30-day return policy on all items. Products must be in original condition with tags attached. Please contact customer support to initiate a return.\n",
                "\n",
                "Example 2:\n",
                "Question: How long does shipping take?\n",
                "Answer: Standard shipping takes 5-7 business days. Express shipping (2-3 days) is available at checkout for an additional fee.\n",
                "\n",
                "Example 3:\n",
                "Question: Can I cancel my order?\n",
                "Answer: You can cancel your order within 2 hours of placing it. After that, please wait for delivery and use our return process.\n",
                "\"\"\"\n",
                "\n",
                "def ask_few_shot(question):\n",
                "    prompt = f\"\"\"You are a helpful customer service assistant for an online store.\n",
                "Here are some example conversations:\n",
                "{few_shot_examples}\n",
                "Now answer this question in the same style:\n",
                "\n",
                "Question: {question}\n",
                "Answer:\"\"\"\n",
                "    \n",
                "    response = generator(prompt)[0]['generated_text']\n",
                "    return response.strip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test few-shot on the same questions\n",
                "print(\"üìã FEW-SHOT RESULTS:\\n\")\n",
                "for q in test_questions:\n",
                "    print(f\"Q: {q}\")\n",
                "    print(f\"A: {ask_few_shot(q)}\")\n",
                "    print(\"-\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Side-by-Side Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare both approaches on a new question\n",
                "test_question = \"My package arrived damaged, what should I do?\"\n",
                "\n",
                "print(f\"üîç COMPARISON for: \\\"{test_question}\\\"\\n\")\n",
                "print(\"=\"*60)\n",
                "print(\"ZERO-SHOT:\")\n",
                "print(ask_zero_shot(test_question))\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"FEW-SHOT:\")\n",
                "print(ask_few_shot(test_question))\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# ‚úèÔ∏è Exercise 1: Improve the System Prompt\n",
                "\n",
                "Modify the zero-shot prompt below to get better responses. Try adding:\n",
                "- Specific instructions about tone (friendly, professional)\n",
                "- Company-specific details (brand name, policies)\n",
                "- Response format requirements (length, structure)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úèÔ∏è YOUR CODE: Create an improved zero-shot prompt\n",
                "\n",
                "def ask_improved_zero_shot(question):\n",
                "    # Modify this prompt to get better responses!\n",
                "    prompt = f\"\"\"You are a helpful customer service assistant for an online store.\n",
                "Answer the following customer question:\n",
                "\n",
                "Question: {question}\n",
                "Answer:\"\"\"\n",
                "    \n",
                "    # HINT: Try adding instructions like:\n",
                "    # - \"Keep your response under 2 sentences\"\n",
                "    # - \"Always be friendly and apologize if there's a problem\"\n",
                "    # - \"Our company name is TechStore and we sell electronics\"\n",
                "    \n",
                "    response = generator(prompt)[0]['generated_text']\n",
                "    return response.strip()\n",
                "\n",
                "# Test your improved prompt\n",
                "print(\"Testing improved prompt...\")\n",
                "print(ask_improved_zero_shot(\"My package arrived damaged, what should I do?\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# ‚úèÔ∏è Exercise 2: Add Few-Shot Examples\n",
                "\n",
                "Add **3 more examples** to the few-shot prompt. Focus on edge cases:\n",
                "- Complaints or frustrated customers\n",
                "- Technical questions about products\n",
                "- Requests the company can't fulfill"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úèÔ∏è YOUR CODE: Add 3 more examples\n",
                "\n",
                "my_examples = \"\"\"\n",
                "Example 4:\n",
                "Question: [YOUR QUESTION HERE]\n",
                "Answer: [YOUR ANSWER HERE]\n",
                "\n",
                "Example 5:\n",
                "Question: [YOUR QUESTION HERE]\n",
                "Answer: [YOUR ANSWER HERE]\n",
                "\n",
                "Example 6:\n",
                "Question: [YOUR QUESTION HERE]\n",
                "Answer: [YOUR ANSWER HERE]\n",
                "\"\"\"\n",
                "\n",
                "# Combined examples\n",
                "all_examples = few_shot_examples + my_examples\n",
                "\n",
                "def ask_expanded_few_shot(question):\n",
                "    prompt = f\"\"\"You are a helpful customer service assistant for an online store.\n",
                "Here are some example conversations:\n",
                "{all_examples}\n",
                "Now answer this question in the same style:\n",
                "\n",
                "Question: {question}\n",
                "Answer:\"\"\"\n",
                "    \n",
                "    response = generator(prompt)[0]['generated_text']\n",
                "    return response.strip()\n",
                "\n",
                "# Test with a challenging question\n",
                "print(\"Testing expanded few-shot...\")\n",
                "print(ask_expanded_few_shot(\"This is ridiculous! I've been waiting 3 weeks for my order!\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# ‚úèÔ∏è Exercise 3: Decision Framework\n",
                "\n",
                "Based on what you've learned, fill out this decision table for when to use each approach:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Your Decision Framework:\n",
                "\n",
                "| Scenario | Best Approach | Why? |\n",
                "|----------|--------------|------|\n",
                "| Quick prototype for a demo | *Your answer* | *Your reason* |\n",
                "| Production chatbot handling 1000s of queries/day | *Your answer* | *Your reason* |\n",
                "| Highly regulated industry (healthcare, finance) | *Your answer* | *Your reason* |\n",
                "| Small startup with limited budget | *Your answer* | *Your reason* |\n",
                "| Enterprise with 100,000 historical support tickets | *Your answer* | *Your reason* |\n",
                "\n",
                "---\n",
                "\n",
                "**Summary Question**: A retail company asks you whether they should fine-tune a model or use few-shot prompting for their customer service bot. They have 500 historical customer-agent conversations. What's your recommendation and why?\n",
                "\n",
                "*Your recommendation:*\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Summary: The Prompting ‚Üí Fine-Tuning Spectrum\n",
                "\n",
                "| Method | Pros | Cons | When to Use |\n",
                "|--------|------|------|-------------|\n",
                "| **Zero-shot** | No setup, instant | Generic, inconsistent | Prototyping, exploration |\n",
                "| **Few-shot** | Quick improvement, flexible | Limited examples, longer prompts | MVPs, moderate customization |\n",
                "| **Fine-tuning** | Consistent, domain-specific | Requires data & compute | Production, specialized domains |\n",
                "\n",
                "---\n",
                "\n",
                "## üéâ Congratulations!\n",
                "\n",
                "You've completed Module 8! You now understand:\n",
                "- ‚úÖ How to customize LLMs through prompting and fine-tuning\n",
                "- ‚úÖ Trade-offs between different approaches\n",
                "- ‚úÖ When each approach makes business sense\n",
                "\n",
                "**Key takeaway**: Start simple (prompting), then move to fine-tuning only when you have enough data and a clear business need!"
            ]
        }
    ]
}