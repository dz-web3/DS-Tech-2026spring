{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dz-web3/DS-Tech-2026spring/blob/main/Module8_LLM_Finetuning/Task1_Sentiment_Finetuning.ipynb)\n",
    "\n",
    "**Click the badge above to open this notebook in Google Colab!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Fine-Tuning for Sentiment Analysis\n",
    "\n",
    "**Data Science for Business (Technical) ‚Äî Spring 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Goals\n",
    "\n",
    "In this task, you will:\n",
    "1. **Run** a working sentiment classification model fine-tuned on product reviews\n",
    "2. **Add** your own training examples to customize the model\n",
    "3. **Test** the model on your own text to see how it performs\n",
    "4. **Reflect** on when fine-tuning is the right business choice\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What You Need to Do\n",
    "\n",
    "1. **First**: Run all the cells from top to bottom to see the demo\n",
    "2. **Then**: Complete the 3 exercises marked with ‚úèÔ∏è\n",
    "3. **Finally**: Answer the reflection questions at the end\n",
    "\n",
    "**Estimated time**: 20-30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup (Just Run This Cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU enabled: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Go to Runtime ‚Üí Change runtime type ‚Üí Select T4 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install required libraries (this takes ~1 minute)\n",
    "!pip install transformers datasets evaluate accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Training Data\n",
    "\n",
    "We'll train the model to classify product reviews as **positive** (1) or **negative** (0).\n",
    "\n",
    "Here's our training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data: Product reviews with sentiment labels\n",
    "# label = 1 means POSITIVE, label = 0 means NEGATIVE\n",
    "\n",
    "training_examples = [\n",
    "    # POSITIVE reviews (label = 1)\n",
    "    {\"text\": \"This product exceeded my expectations! Absolutely love it.\", \"label\": 1},\n",
    "    {\"text\": \"Great quality for the price. Would definitely buy again.\", \"label\": 1},\n",
    "    {\"text\": \"Fast shipping and the item works perfectly. Very satisfied!\", \"label\": 1},\n",
    "    {\"text\": \"Best purchase I've made this year. Highly recommend!\", \"label\": 1},\n",
    "    {\"text\": \"The customer service was amazing and the product is fantastic.\", \"label\": 1},\n",
    "    {\"text\": \"Exactly what I needed. Works as described.\", \"label\": 1},\n",
    "    {\"text\": \"Love this product! My whole family uses it now.\", \"label\": 1},\n",
    "    {\"text\": \"Five stars! Couldn't be happier with my purchase.\", \"label\": 1},\n",
    "    \n",
    "    # NEGATIVE reviews (label = 0)\n",
    "    {\"text\": \"Terrible quality. Broke after one week of use.\", \"label\": 0},\n",
    "    {\"text\": \"Waste of money. Does not work as advertised.\", \"label\": 0},\n",
    "    {\"text\": \"Very disappointed. Would not recommend to anyone.\", \"label\": 0},\n",
    "    {\"text\": \"Poor quality and awful customer service.\", \"label\": 0},\n",
    "    {\"text\": \"Arrived damaged and getting a refund was a nightmare.\", \"label\": 0},\n",
    "    {\"text\": \"Complete scam. Nothing like the pictures showed.\", \"label\": 0},\n",
    "    {\"text\": \"Don't buy this. Regret wasting my money.\", \"label\": 0},\n",
    "    {\"text\": \"Stopped working after two days. Total junk.\", \"label\": 0},\n",
    "]\n",
    "\n",
    "print(f\"üìä Training data: {len(training_examples)} examples\")\n",
    "print(f\"   - Positive reviews: {sum(1 for x in training_examples if x['label'] == 1)}\")\n",
    "print(f\"   - Negative reviews: {sum(1 for x in training_examples if x['label'] == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load the Pre-trained Model\n",
    "\n",
    "We'll use **DistilBERT** ‚Äî a smaller, faster version of BERT that's perfect for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,  # 2 classes: positive and negative\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {model_name}\")\n",
    "print(f\"   Parameters: ~66 million\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset format\n",
    "dataset = Dataset.from_list(training_examples)\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "print(\"‚úÖ Data tokenized and ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model üöÄ\n",
    "\n",
    "This will take about **2-3 minutes** on a T4 GPU. Watch the loss decrease!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metric\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Training configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sentiment_model\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    learning_rate=2e-5,\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(\"   Watch the 'loss' value decrease ‚Äî that means the model is learning!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the Fine-Tuned Model\n",
    "\n",
    "Let's see how our trained model performs on new reviews!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment\n",
    "def predict_sentiment(text):\n",
    "    \"\"\"Predict sentiment of a given text\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "        confidence = torch.softmax(outputs.logits, dim=-1).max().item()\n",
    "    \n",
    "    sentiment = \"POSITIVE üòä\" if prediction == 1 else \"NEGATIVE üòû\"\n",
    "    return sentiment, confidence\n",
    "\n",
    "print(\"üéØ Model ready for predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on new reviews (not in training data)\n",
    "test_reviews = [\n",
    "    \"Amazing product! Will definitely purchase again.\",\n",
    "    \"Total garbage. Don't waste your money on this.\",\n",
    "    \"It's okay. Nothing special but does the job.\",\n",
    "    \"My kids absolutely love this toy!\",\n",
    "    \"Broken on arrival. Very frustrating experience.\",\n",
    "]\n",
    "\n",
    "print(\"üìã Testing on new reviews:\\n\")\n",
    "for review in test_reviews:\n",
    "    sentiment, confidence = predict_sentiment(review)\n",
    "    print(f\"Review: \\\"{review}\\\"\")\n",
    "    print(f\"Prediction: {sentiment} (confidence: {confidence:.1%})\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚úèÔ∏è Exercise 1: Add Your Own Training Examples\n",
    "\n",
    "Add **5 new reviews** to the training data below ‚Äî at least 2 positive and 2 negative.\n",
    "\n",
    "Think about reviews that might be challenging for the model:\n",
    "- Mixed opinions (\"Good quality but slow shipping\")\n",
    "- Sarcasm (\"Wow, so great that it broke immediately\")\n",
    "- Industry-specific language\n",
    "\n",
    "**After adding your examples**, run all the cells below to retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è YOUR CODE: Add 5 new training examples here!\n",
    "\n",
    "my_examples = [\n",
    "    # Add your examples below (at least 2 positive, 2 negative)\n",
    "    # Format: {\"text\": \"Your review here\", \"label\": 1}  # 1 = positive\n",
    "    # Format: {\"text\": \"Your review here\", \"label\": 0}  # 0 = negative\n",
    "    \n",
    "    # Example (delete this and add your own):\n",
    "    # {\"text\": \"This laptop runs so smoothly!\", \"label\": 1},\n",
    "    \n",
    "]\n",
    "\n",
    "# Combine with original training data\n",
    "combined_data = training_examples + my_examples\n",
    "\n",
    "print(f\"üìä Combined training data: {len(combined_data)} examples\")\n",
    "print(f\"   - Original: {len(training_examples)}\")\n",
    "print(f\"   - Your additions: {len(my_examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with combined data (only run this after adding your examples!)\n",
    "if len(my_examples) >= 5:\n",
    "    print(\"üîÑ Retraining model with your examples...\\n\")\n",
    "    \n",
    "    # Reload fresh model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=2,\n",
    "        id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "        label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "    )\n",
    "    \n",
    "    # Prepare new dataset\n",
    "    new_dataset = Dataset.from_list(combined_data)\n",
    "    new_tokenized = new_dataset.map(tokenize, batched=True)\n",
    "    \n",
    "    # Train\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=new_tokenized,\n",
    "    )\n",
    "    trainer.train()\n",
    "    print(\"\\n‚úÖ Retrained with your examples!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please add at least 5 examples to my_examples list above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚úèÔ∏è Exercise 2: Test on Your Own Text\n",
    "\n",
    "Write **3 product reviews** to test the model. Try to find cases where the model might be wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è YOUR CODE: Test your own reviews!\n",
    "\n",
    "my_test_reviews = [\n",
    "    # Add your test reviews here:\n",
    "    \"Your first review here\",\n",
    "    \"Your second review here\",\n",
    "    \"Your third review here\",\n",
    "]\n",
    "\n",
    "print(\"üìã Testing your reviews:\\n\")\n",
    "for review in my_test_reviews:\n",
    "    sentiment, confidence = predict_sentiment(review)\n",
    "    print(f\"Review: \\\"{review}\\\"\")\n",
    "    print(f\"Prediction: {sentiment} (confidence: {confidence:.1%})\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚úèÔ∏è Exercise 3: Compare Before and After \n",
    "\n",
    "Think about the difference between using a pre-trained model vs. your fine-tuned model.\n",
    "\n",
    "**Answer these questions** (edit the text below):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answers:\n",
    "\n",
    "**Q1: Did the model correctly classify all your test reviews? Which ones did it get wrong and why do you think that happened?**\n",
    "\n",
    "*Your answer here:* \n",
    "\n",
    "---\n",
    "\n",
    "**Q2: If you were building a sentiment analysis system for a specific industry (e.g., restaurants, hotels, tech products), what kind of training data would you need?**\n",
    "\n",
    "*Your answer here:*\n",
    "\n",
    "---\n",
    "\n",
    "**Q3: When would a company choose fine-tuning vs. just using better prompts with ChatGPT? Name one advantage of each approach.**\n",
    "\n",
    "*Your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully:\n",
    "- ‚úÖ Fine-tuned a language model for sentiment classification\n",
    "- ‚úÖ Added your own training examples\n",
    "- ‚úÖ Tested the model on custom inputs\n",
    "- ‚úÖ Thought about business applications of fine-tuning\n",
    "\n",
    "**Next**: Complete Task 2 to compare fine-tuning with prompting approaches!"
   ]
  }
 ]
}
